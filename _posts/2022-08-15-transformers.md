---
title: "Transformers in remote sensing"
description: "Introduction to Transformers and why you should care"
layout: post
categories: [markdown]
toc: true
image: images/transformers/transformer.jpg
show_image: true
hide: true
comments: true
---

## Introduction
paper on arXiv[^1]

<blockquote class="twitter-tweet tw-align-center"><p lang="en" dir="ltr">What questions do people have about Transformers and their use in remote sensing? This is the topic of my next blog post üôá‚Äç‚ôÇÔ∏èüöÄ</p>&mdash; Robin Cole (@robmarkcole) <a href="https://twitter.com/robmarkcole/status/1554348041926311937?ref_src=twsrc%5Etfw">August 2, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

What is a Transformer Model? A neural network architecture published in a 2017 paper titled [Attention Is All You Need](https://arxiv.org/abs/1706.03762). Transformers learn context by tracking relationships in sequential data using a technique called attention. Transformers are replacing CNNs and RNNs in many applications and have come to dominate the field of natural language processing (NLP). [Ref and further reading](https://blogs.nvidia.com/blog/2022/03/25/what-is-a-transformer-model/)



## Footnotes
[^1]: https://arxiv.org/abs/2207.06418
