<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>A brief introduction to satellite image classification with neural networks | Blog of Robin Cole</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="A brief introduction to satellite image classification with neural networks" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="What is image classification, which models are used and how to approach your first project" />
<meta property="og:description" content="What is image classification, which models are used and how to approach your first project" />
<link rel="canonical" href="https://robmarkcole.com/markdown/2022/09/24/satellite-image-classification.html" />
<meta property="og:url" content="https://robmarkcole.com/markdown/2022/09/24/satellite-image-classification.html" />
<meta property="og:site_name" content="Blog of Robin Cole" />
<meta property="og:image" content="https://robmarkcole.com/images/classification/classification-main.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-09-24T00:00:00-05:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://robmarkcole.com/images/classification/classification-main.png" />
<meta property="twitter:title" content="A brief introduction to satellite image classification with neural networks" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-09-24T00:00:00-05:00","datePublished":"2022-09-24T00:00:00-05:00","description":"What is image classification, which models are used and how to approach your first project","headline":"A brief introduction to satellite image classification with neural networks","image":"https://robmarkcole.com/images/classification/classification-main.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://robmarkcole.com/markdown/2022/09/24/satellite-image-classification.html"},"url":"https://robmarkcole.com/markdown/2022/09/24/satellite-image-classification.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://robmarkcole.com/feed.xml" title="Blog of Robin Cole" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-235705291-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-235705291-1');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Blog of Robin Cole</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">A brief introduction to satellite image classification with neural networks</h1><p class="page-description">What is image classification, which models are used and how to approach your first project</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-09-24T00:00:00-05:00" itemprop="datePublished">
        Sep 24, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      9 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#markdown">markdown</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#introduction">Introduction</a></li>
<li class="toc-entry toc-h2"><a href="#what-is-image-classification">What is image classification?</a></li>
<li class="toc-entry toc-h2"><a href="#image-classification-datasets">Image classification datasets</a></li>
<li class="toc-entry toc-h2"><a href="#selecting--training-models">Selecting &amp; training models</a></li>
<li class="toc-entry toc-h2"><a href="#how-to-approach-your-first-classification-project">How to approach your first classification project</a></li>
<li class="toc-entry toc-h2"><a href="#summary">Summary</a></li>
<li class="toc-entry toc-h2"><a href="#footnotes">Footnotes</a></li>
</ul><h2 id="introduction">
<a class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction</h2>
<p>On <a href="https://twitter.com/robmarkcole">Twitter</a> &amp; <a href="https://www.linkedin.com/in/robmarkcole/">LinkedIn</a> I regularly post on the topic of deep learning applied to satellite &amp; aerial imagery, and I receive many messages from people who are new to the field and are seeking introductory level material. I maintain a popular repository on Github called the <a href="https://github.com/robmarkcole/satellite-image-deep-learning">satellite-image-deep-learning</a> which lists many useful references, ranging from very introductory articles to the code for cutting edge techniques published in the academic literature. However this long list of references is not necessarily that approachable to people getting started, so I am going to publish a series of short blog posts introducing the main techniques listed in my repository. This first post is on image classification of satellite imagery, which has many practical applications and is ideal for practicing the basics of deep learning. There is no code to follow in this post, but an introduction to the topic and a general description of the process. I aim to publish usable notebooks in the near future. Lets get started!</p>

<h2 id="what-is-image-classification">
<a class="anchor" href="#what-is-image-classification" aria-hidden="true"><span class="octicon octicon-link"></span></a>What is image classification?</h2>
<p>You may already be familiar with image classification from seeing the numerous cats vs dogs image classification tutorials on the internet. Image classification is therefore the task of assigning a single label to an image, or even assigning multiple labels to an image<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>. Note however that the term ‘classification’ can mean different things to different people - in particular in many articles classification may be used to describe pixel or pixel-cluster level labels, which I would call semantic segmentation. To be clear here we are discussing single labels applied to single images, using deep learning neural networks to generate the label.</p>

<p>When applied to satellite imagery, single label classification has two common uses:</p>

<ul>
  <li>label the dominant subject of image, e.g. golf course, harbour</li>
  <li>perform binary detection of some subject, e.g. ship present or not, deforested or not</li>
</ul>

<p>There are also more advanced classification techniques, for example using a time-series of images to classify crops where the unique seasonal changes are a strong indicator of crop type. I aim to create a later blog post discussing these techniques also, but if you are interested to read more these are under the <a href="https://github.com/robmarkcole/satellite-image-deep-learning#time-series">Time series</a> section of my repository.</p>

<h2 id="image-classification-datasets">
<a class="anchor" href="#image-classification-datasets" aria-hidden="true"><span class="octicon octicon-link"></span></a>Image classification datasets</h2>
<p>To get more familiar with satellite image classification I recommend exploring a couple of benchmark datasets<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>, such as the UC Merced dataset (a sample of which is shown below) or the EuroSAT dataset. Both of these datasets are available in the standard RGB/single label format, but also in more interesting multi-class versions. For these and other datasets see the <a href="https://github.com/robmarkcole/satellite-image-deep-learning/blob/master/assets/datasets.md">Datasets</a> section on my repository.</p>

<p><img src="https://www.researchgate.net/publication/324924412/figure/fig4/AS:644015246544898@1530556608631/Example-images-from-the-UC-Merced-dataset.png" alt="" title="The UC Merced dataset"></p>

<h2 id="selecting--training-models">
<a class="anchor" href="#selecting--training-models" aria-hidden="true"><span class="octicon octicon-link"></span></a>Selecting &amp; training models</h2>
<p>The <a href="https://github.com/robmarkcole/satellite-image-deep-learning#classification">Classification</a> section in my repository lists many different resources demonstrating the training of classification models on satellite imagery. In fact it is relatively rare to train a model from scratch on your own dataset, and far more common to use a model that has been pre-trained on a benchmark dataset (usually <a href="https://en.wikipedia.org/wiki/ImageNet">ImageNet</a>) and then fine-tune this model on your own dataset. To learn more about fine-tuning I recommend the <a href="https://d2l.ai/chapter_computer-vision/fine-tuning.html">fine-tuning lesson on d2l.ai</a>. In fine-tuning the feature extraction layers are frozen, and only the fully connected classification layers are updated:</p>

<p><img src="https://api.intechopen.com/media/chapter/64395/media/F5.png" alt="" title="Strategy of fine-tuning deeper layers of AlexNet."></p>

<p>The internet regularly reports new ‘state of the art’ models which improve performance on some benchmark dataset or other, and it would be reasonable to assume that the latest and greatest models are usually used in applications. However for an approachable article comparing models I highly recommend reading <a href="https://www.kaggle.com/code/jhoward/the-best-vision-models-for-fine-tuning/notebook">The best vision models for fine-tuning</a> by Jeremy Howard. In this article Jeremy compares 86 models on two benchmark datasets; the <a href="https://www.robots.ox.ac.uk/~vgg/data/pets/">IIT Pet dataset</a> and the <a href="https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/data">Kaggle Planet dataset</a> (a remote sensing dataset). He shows that the modern models (the vit is a <a href="https://robmarkcole.com/markdown/2022/08/15/transformers.html">Transformer model</a>) are indeed the top performers in terms of accuracy, shown in the table below:</p>

<p><img src="https://raw.githubusercontent.com/robmarkcole/blog/master/images/classification/table.png" alt="" title="The top 10 performers on the Planet dataset"></p>

<p>Interestingly the best performers vary between the Pets and Planet datasets, and Jeremy attributes this to the fact that the Planet dataset does not resemble the images in the ImageNet dataset (which most models are pre-trained on), so the models which learn new features the fastest are the best performers. He also notes that “there’s little correlation between model size and performance” on the Planet dataset, and therefore advises selecting smaller models (which will also be faster in use). An additional advantage of choosing a small model is that the pace of experimentation is faster. For me a surprising result on the Planet dataset is that the relatively old (<a href="https://arxiv.org/abs/1512.03385">published in 2015</a>) Resnet 18 model is in the top 10 performers. As Jeremy says, “Resnet 18 has very low memory use, is fast, and is still quite accurate”, and for these reasons I suggest it is a good default model to begin projects with.</p>

<h2 id="how-to-approach-your-first-classification-project">
<a class="anchor" href="#how-to-approach-your-first-classification-project" aria-hidden="true"><span class="octicon octicon-link"></span></a>How to approach your first classification project</h2>
<p>Perhaps you already have a use case for classification from your day job, but if not I suggest deciding on a topic that interests you (e.g. deforestation, crop classification) and finding a relevant dataset on <a href="https://www.kaggle.com/">Kaggle</a>, <a href="https://roboflow.com/robincoledata">Roboflow data hub</a>, or in my repository. There are also regular competitions run by organisations including ESA and the <a href="https://www.radiant.earth/">Radiant Earth Foundation</a>, and these typically provide a dataset and an exciting challenge. Begin by following a tutorial on fine-tuning a vision model (e.g. the <a href="https://d2l.ai/chapter_computer-vision/fine-tuning.html">fine-tuning lesson on d2l.ai</a>) and then adapt it to use your chosen dataset. You will probably encounter some challenges just from switching dataset alone, such as dealing with different sized images or number of channels. If you are not particularly familiar with geospatial images (geotiffs) then I recommend sticking to datasets where the images are simply png or jpgs. If you do want to work with geospatial images you will probably need to ‘chip’ large images into smaller training chips, and I list many tools to do this on my repository <a href="https://github.com/robmarkcole/satellite-image-deep-learning/blob/master/assets/software.md#image-chippingtiling--merging">here</a>. Once you have assembled your dataset you will probably have to modify the model training code for loading and preprocessing the dataset, and this is a good opportunity to practice your Python programming skills and get familiar with your chosen deep learning framework (Tensorflow or Pytorch). Note that the UC Merced &amp; EuroSAT dataset can be accessed via the <a href="https://www.tensorflow.org/datasets/catalog/overview">Tensorflow</a> data hub, simplifying the process of using this dataset. Pytorch users will want to access these datasets via <a href="https://torchgeo.readthedocs.io/en/latest/_modules/torchgeo/datamodules/ucmerced.html">torchgeo</a>, and will also benefit from much additional functionality that simplifies working with geospatial datasets.</p>

<p>Moving on to model fine-tuning, begin experimenting to see which factors improve or degrade model performance. You will find that data augmentation and training parameters such as batch size and number of epochs will have a significant impact on the models performance. I recommend reading about under and over-fitting, and performing experiments to demonstrate these issues so that you will recognise them when they occur. In my experience 
over-fitting is quite common, and you should visualise your training losses to identify it. The figure below is from the post <a href="https://medium.com/mlearning-ai/underfitting-and-overfitting-in-deep-learning-687b1b7eb738">Underfitting and Overfitting in Deep Learning</a></p>

<p><img src="https://miro.medium.com/max/1400/1*pgQzuW_Wava2aHcVBsaXbw.png" alt="" title="Over fitting can be identified when training loss is decreasing but validation loss is increasing"></p>

<p>Once you have gained confidence fine-tuning a model on a published dataset, you could move on to creating your own dataset. A classification dataset can be created by downloading images from Google Earth, using one of the scripts listed on my repository <a href="https://github.com/robmarkcole/satellite-image-deep-learning/blob/master/assets/software.md#image-dataset-creation">here</a>. If you are unsure which tool to use I suggest first checking out <a href="https://github.com/AliFlux/MapTilesDownloader">Map Tiles Downloader</a> which provides a helpful UI <sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup>. To prepare the dataset for training it will be necessary to sort your images into folders where the folder name is the label that will be used for that class. Fortunately this can be done using just the file browser on your computer, and no special ‘annotation’ software is required. If you’re interested in a tool to better understand and curate your classification data, I recommend <a href="https://roboflow.com/robincole">Roboflow</a>. You can also use Roboflow to have a hosted model API after training your custom model.</p>

<p>The classification accuracy you can achieve roughly depends on 3 factors:</p>
<ul>
  <li>The quality of the input images; including appropriate image pre-processing, spatial &amp; radiometric resolution of the images</li>
  <li>Quality, quantity and balance of the training dataset and labels</li>
  <li>Selection and fine-tuning of the deep learning model</li>
</ul>

<p>At this point you may wish to write a blog post about your project, or simply publish a notebook on Kaggle. I personally think that summarising and presenting your work is an important part of the learning process, and recommend doing it even for small projects. If you want to take your project to the next level, consider creating a web app or API to provide a live service which you can use to demonstrate the model. There are a few examples of how to do this in my repository <a href="https://github.com/robmarkcole/satellite-image-deep-learning/blob/master/assets/software.md#web-apps">here</a> and <a href="https://github.com/robmarkcole/satellite-image-deep-learning/blob/master/assets/deployment.md">here</a>. Note that if you want to deploy a production ready service there may be a significant amount of engineering required to handle pre-processing of the uploaded images, for example to handle multiple images types, detect quality issues etc. This is beyond the scope of this post but is another topic I am considering doing a post on.</p>

<h2 id="summary">
<a class="anchor" href="#summary" aria-hidden="true"><span class="octicon octicon-link"></span></a>Summary</h2>
<p>I hope that this has been a useful introduction to satellite imagery classification, and provided an interesting overview of how models are trained in practice. As mentioned in the introduction, in the future I plan on publishing notebooks which you will actually be able to work through. In the meantime I am seeking feedback on what challenges people have getting started, so I can incorporate this into the notebooks. Feel free to drop your feedback in the comments section below, or send me a message online. In the meantime I recommend joining up to the <a href="https://www.linkedin.com/groups/12698393/">satellite-image-deep-learning LinkedIn group</a> where there is daily material on the topic of deep learning on satellite imagery. Thanks for reading this far and I look forward to connecting soon!</p>

<h2 id="footnotes">
<a class="anchor" href="#footnotes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Footnotes</h2>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>When there are <strong>more</strong> than one label to be associated with an image the task is usually referred to as ‘multi-class’ or ‘multi-label’ classification. This more complex task is beyond the scope of this post but I aim to revisit in a later post. If you are keen to explore this topic already checkout the Medium article <a href="https://towardsdatascience.com/multi-label-land-cover-classification-with-deep-learning-d39ce2944a3d">Multi-label Land Cover Classification with Deep Learning</a> <a href="#fnref:1" class="reversefootnote" role="doc-backlink">↩</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>A benchmark dataset is a dataset that is used as a standard by the community to compare the performance of different techniques <a href="#fnref:2" class="reversefootnote" role="doc-backlink">↩</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>My understanding is that it is perfectly legal to access Google Earth imagery in this way for non commercial purposes. If in doubt seek advice from your company or university legal team <a href="#fnref:3" class="reversefootnote" role="doc-backlink">↩</a></p>
    </li>
  </ol>
</div>

  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="robmarkcole/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/markdown/2022/09/24/satellite-image-classification.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/robmarkcole" target="_blank" title="robmarkcole"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/robmarkcole" target="_blank" title="robmarkcole"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a rel="me" href="https://twitter.com/robmarkcole" target="_blank" title="robmarkcole"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
